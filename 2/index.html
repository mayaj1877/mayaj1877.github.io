<!DOCTYPE html>
<html>
<head>
    <title>Project 2</title>
    <title> Project 2: Fun with Filters and Frequencies </title>
    <style>
        body {
            font-family: Georgia, Times New Roman, Arial, sans-serif;
            margin: 40px;
            padding: 40px;
        }

        .container {
            max-width: 800px;
            margin: 40px;
            padding: 40px;
            text-align: center;
        }

        .image-row {
            display: flex;
            justify-content: center; 
            gap: 20px;
        }

        .image-row img {
            max-width: 100%;  
            height: auto;     
            object-fit: contain;
        }

        figure {
            text-align: center;
        }
 
        .center-text {
            text-align: center; 
        }
        
    </style>
    
</head>
<body>
    <h1> Project 2: Fun with Filters and Frequencies! </h1>
    <h2> by Maya Joiner </h2>

    
    <h2> Part 1: Fun with Filters </h2>

    <p> In this part, I take the partial derivatives of the Cameraman image in both the x direction and the y direction. One notable difference between the two is that the partial derivative with respect to x highlights vertical edges, while the partial derivative with respect to y highlights horizontal edges. Once I take the partial derivatives, I get the gradient magnitude by taking the square root of a sum of the squares of the x and y partial derivatives. I can choose how strong I want the edges to be by limiting the magnitude to a certain threshold. For example, a threshold of 0 would show every single edge possible (resulting in almost a white image), while a threshold of 1 (and about 0.7 in the case of the Cameraman image) would show a black image because no edges are visible. After fidgeting with the thresholds, I found that 0.3 was a perfect threshold where the edges of the man get highlighted without the edges of the background getting highlighted. </p>

    <div class="image-row">
    <p><img src="media/1.1 dx_dy_gradient_magnitude.png" /></p>
    </div>

    <div class="image-row">
    <p><img src="media/1.1 edge-image.png" /></p>
    </div>

    <p> However, even the best threshold doesn't completely get rid of the unnecessary noise/edges. Therefore, I try a different approach: a lowpass filter, where only low frequencies of an image are shown. To create a lowpass filter, I first blur the image and then convolve that blurred image with a 2D Gaussian filter. Here is the result: </p>

    <div class="image-row">
    <p><img src="media/1.2 blurred dx, dy, gradmag.png" /></p>
    </div>

    <p> <b> DIFFERENCES: </b> Compared to the non-blurred partial derivatives, the blurred version has more apparent edges, and the images look more dented/bumpy in general. </p>

    <p> Another thing I did was to take the DoG (Derivative of Gaussian) filters (which, as its name suggests, is a convolution of the 2D Gaussian and the non-blurred partial derivatives. They look like this: </p>

    <div class="image-row">
    <p><img src="media/1.2 dog_dx.png" /></p>
    <p><img src="media/1.2_dog_dy.png" /></p>
    </div>

    <figure>
    <p> left: DoG Dx, right: Dog Dy </p>
    </figure>

    <p> However, this yielded <b>the same</b> image as the blurred version: </p>
    <div class="image-row">
    <p><img src= "media/1.2_regular_vs_dog_blur.png" /> </p>
    </div>

    <h2> Part 2: Fun with Frequencies </h2>
    <h3> Part 2.1: Image Sharpening</h3>

    <p> A lowpass filter blurred the image, but a highpass filter (i.e. taking just the high frequencies of the image) sharpens the image. A high pass filter is actually just the low frequencies taken out of the original image, i.e. image - lowpass_image. Compared to the orignal image, the sharpened version has more distinct edges, but the colors look more blunt. To me, I like the regular version better than the sharpened version because the regular version feels more smooth. </p>

    <div class="image-row">
    <p><img src="media/2.1_source_taj.jpg" /></p>
    <p><img src="media/2.1_taj.png" /></p>
    </div>

    <figure>
    <p> left: original Taj, right: sharpened Taj </p>
    </figure>

    <h4> Sharpening My Own Photo: Statue at Okinawa, Japan </h4>
    <div class="image-row">
    <p><img src="media/2.1_source_okinawa.png" /></p>
    <p><img src="media/2.2_okinawa.png" /></p>
    </div>

    <figure>
    <p> left: original statue, right: sharpened statue </p>
    <p> <b> Note:</b> I had issues saving the image that make this image a bit darker and less accurate. A more accurate version of the sharpened image is in my jupyter notebook. </p>
    </figure>

    <h3> Part 2.2: Hybrid Images </h3>

    In his famous painting of the Mona Lisa, Leonardo Da Vinci implemented cool technology using lowpass and highpass frequencies. If you take just the high frequencies of the Mona Lisa (i.e. look directly at it), she's looking away, frowning. However, if you take just the low frequencies (i.e. use your peripheral vision), she looks like she's looking at you, smiling. Da Vinci combined these frequencies to make the Mona Lisa look like her eyes are following you when you walk away! We can use this same technology to make photos that look like one thing close up, but look like something else from a distance.

    <h4> Image: Man and Cat </h4>
    <div class="image-row">
    <p><img src="media/2.2_source_derek.jpg" /></p>
    <p><img src="media/2.2_source_cat.jpg" /></p>
    </div>

    <p> becomes... </p>
    
    <div class="image-row">
    <p><img src="media/2.2_hybrid_mancat.png" /></p>
    </div>

    <h4> Using My Own Photos:</h4>

    <h5>  Mario and Luigi  </h5>
    <div class="image-row">
    <p><img src="media/2.4_source_mario.png" /></p>
    <p><img src="media/2.4_source_luigi.png" /></p>
    </div>
    
    <div class="image-row">
    <p><img src="media/2.2_hybrid_marioluigi.png" /></p>
    </div>

    <h5>  Mario and Luigi: Frequency Analysis  </h5>
    <div class="image-row">
    <p><img src="media/2.2_freq_mario.png" /></p>
    <p><img src="media/2.2_freq_luigi.png" /></p>
    <p><img src="media/2.2_freq_marioluigi.png" /></p>
    </div>

    <h5> Nessie Exists??? </h5>
    <p> I'm a big fan of Nessie. A lot of people think it doesn't exist, but some people claim they saw it and took photos of it. Is it the case they actually saw a giraffe with fins of a turtle? </p>
    <div class="image-row">
    <p><img src="media/2.3_source_giraffe.jpg" /></p>
    <p><img src="media/2.3_source_turtle.jpg" /></p>
    </div>
    
    <div class="image-row">
    <p><img src="media/2.2_nessie??.png" /></p>
    </div>

    <h5> Nessie: Frequency Analysis  </h5>
    <div class="image-row">
    <p><img src="media/2.2_freq_giraffe.png" /></p>
    <p><img src="media/2.2_freq_turtle.png" /></p>
    <p><img src="media/2.2_freq_nessie.png" /></p>
    </div>

    <h5> Failure Case: Monkey Side-eye Meme</h5>
    <p> This one was a failure because the two images were too similar evrywhere except the eyes, that it ended up just making the eyes look weird. Hopefully I can use this monkey image for something else... </p>
    <div class="image-row">
    <p><img src="media/2.2_source_monkey_sideeye.png" /></p>
    <p><img src="media/2.2_source_monkey_normal.png" /></p>
    <p><img src="media/2.2_hybrid_monkey.png" /></p>
    </div>

    <h3> Part 2.3: Gaussian and Laplacian Stacks </h3>

    <p> In this section, I implement a Gaussian and Laplacian Stack for images of an apple and orange. At every layer of the Gaussian stack, a lowpass filter is applied (i.e. the image gets blurred). A kth layer of the laplacian stack takes the difference between the kth layer of the Gaussian layer stack and its upscaled image (i.e. k+1th layer of the Gaussian stack, because stacks are first in, last out). </p>

    <div class="image-row">
    <p><img src="media/2.4_source_apple.jpeg" /></p>
    <p><img src="media/2.4_source_orange.jpeg" /></p>
    </div>

    <div class="image-row">
    <p><img src="media/2.3_gaussian_stacks.png" /></p>
    <p><img src="media/2.3_laplacian_stacks.png" /></p>
    </div>

    <figure>
    <p> left: Gaussian stack, right: Laplacian stack </p>
    </figure>

    <h3> Part 2.4: Multiresolution Blending </h3>
    <p> Using a black and white mask image, I created a Gaussian stack of the mask in order to blend the apple and the orange together. The equation is pretty simple: Image = mask * Image_A + (1-mask) * Image_B (and this applies to each layer of the laplacian pyramid). </p>

    <div class="image-row">
    <p><img src="media/2.4_source_apple.jpeg" /></p>
    <p><img src="media/2.4_source_orange.jpeg" /></p>
    <p><img src="media/2.4_mask.png" /></p>
    </div>

    <p> becomes... </p>
    <div class="image-row">
    <p><img src="media/2.4_oraple.png" /></p>

    <h4> Using My Own Photos:</h4>

    <h5>  Monkey-Gorillaz  </h5>

    <p> The monkey wasn't good at hybrid images, but perhaps it is good for blending... </p>
    <div class="image-row">
    <p><img src="media/2.2_source_monkey_normal.png" /></p>
    <p><img src="media/2.4_source_gorilla.png" /></p>
    <p><img src="media/2.4_monkey-mask.png" /></p>
    <p><img src="media/2.4_gorilla_monkey.png" /></p>
    </div>

    <h5>  Irregular Mask: Mimikyu  </h5>

    <div class="image-row">
    <p><img src="media/2.4_source_maya.png" /></p>
    <p><img src="media/2.4_souorce_mimikyu.png" /></p>
    <p><img src="media/2.4_source_mimikyu_mask.png" /></p>
    <p><img src="media/2.4_mimikyu_maya.png" /></p>
    </div>
    
</body>
</html>
