<!DOCTYPE html>
<html>
<head>
    <title>Project 3: </title>
    <title> Project 3: Face Morphing </title>
    <style>
        body {
            font-family: Georgia, Times New Roman, Arial, sans-serif;
            margin: 40px;
            padding: 40px;
        }

        .container {
            max-width: 800px;
            margin: 40px;
            padding: 40px;
            text-align: center;
        }

        .image-row {
            display: flex;
            justify-content: center; 
            gap: 0;
        }

        .image-row img {
            width: 200px;  
            height: auto;     
            object-fit: contain;
        }

        .big-row img {
            width: 400px; 
            height: 400px;    
            object-fit: contain;
            padding: 0;    
            margin: 0;    
            border: none;  
            gap: 0;
        }

        .mid-row img {
            width: 200px; 
            height: 200px;    
            padding: 0;    
            margin: 0;    
            border: none;  
            gap: 0;
        }

        figure {
            text-align: center;
        }
 
        .center-text {
            text-align: center; 
        }
        
    </style>
    
</head>
<body>
    <h1> Project 3: Face Morphing </h1>
    <h2> by Maya Joiner </h2>

    
    <h2> Part 1: Defining Correspondences </h2>

    <p> In this part, I use the ginput function to assign points to both images that i want to morph together. I used a photo of myself and an idol named Wonyoung. In this section only, I call the Delaunay function on the points for each image to get a Delaunay triangulation unique to that photo. These trianguulations are made just for this part -- I will instead be using a Delaunay triangulation of the <b> mean </b> points of both images for part 2.  </p>

  <p> Three key lessons that caused me to struggle with this problem were that: 1) The images have to be <b> very </b> aligned (looking in the same direction, same angle, same <b> face </b> size, etc), 2) the points have to be labeled <b> in the same order for both images </b> (ex. if point 4 is on my eye, point 4 also has to be on Wonyoung's eye as well, and 3) I need to include the corners of the photos in my point set. Even though both im1 and im2 had the same photo size (ex. 750x900), the face sizes were different (i.e. Wonyoung was zoomed in so her face was bigger), so my morph didn't look that good. To mitigate this issue, I added a border to Wonyoung's photo and shrinked the photo inside the border so that our face sizes would be more similar. </p>

    <h4> Original Images </h4>
    <div class="image-row mid-row">
    <p><img src="media/maya.png" /></p>
    <p><img src="media/wony.png" /></p>
    </div>

    <h4> Point Ordering and Delaunay Triangulations </h4>
    <div class="image-row big-row">
    <p><img src="media/points order.png" /></p>
    <p><img src="media/maya_delaunay.png" /></p>
    <p><img src="media/wony_delaunay.png" /></p>
    </div>

    <h2> Part 2: The Mid-Way Face </h2>

    <p> In this part, I create one singular morph -- an image that is exactly halfway between im1 and im2. This can be done with a simple crossblur equation: </p>

    <p> (1-t) * im1 + t * im2 </p>
        
    <p> Where t is the blur factor, between 0 and 1. In this case, I want a halfway face so I set t to 0.5. A vanilla morph (without any transformations) would look like: </p>

    <div class="image-row big-row">
    <p><img src="media/vanilla.png" /></p>
    </div>
    
    <p> However, this halfway face just looks like two faces overlayed. It doesn't actually transform my face onto a mean face. Therefore, I calculate a mean face and then transform my face onto the mean face. Then, I tranform Wonyoung's face onto the mean face, and crossblur the resulting transformed images using the crossblur equation. Therefore, instead of using individual Delaunays, I take an average of image 1 and image 2's points and average them to create a Delaunay triangulation based on the mean points. </p>

    <div class="image-row big-row">
    <p><img src="media/mean_delaunay_maya.png" /></p>
    <p><img src="media/mean_delaunay_wony.png" /></p>
    </div>

<p> Now I have both my image (image 1)'s points and the mean points, and the mean triangles. For each triangle, I get the relevant points values of that triangle for both my image and the mean image. Mathematically, an affine matrix multiplied by the original points warps the points to the mean points. However, according to the lecture an inverse warp is better, so instead we warp the mean points onto the original points. Then, I average the colors via bilinear interpolation. </p>

    <h4> morphed maya --> mid-way face <-- morphed wonyoung </h4>
    
    <div class="image-row big-row">
    <p><img src="media/maya_morph_final.png" /></p>
    <p><img src="media/halfway_image.png" /></p>
    <p><img src="media/wony_morph_final.png" /></p>
    </div>

<p> <b> Aside: </b> There are a few methods in Ed that all perform bilinear interpolation: griddata, interp2d, regular grid interpolator, etc. Initially I used griddata as the spec suggested, but that gave my photos white streaks, so I used interp2d instead (interp2d has its flaws too though -- it is slower than griddata and also sometimes produces black dots). However, when debugging my griddata function I noticed there are multiple ways to interpolate (other than bilinear). The griddata function offered a few options, so I tried them: </p>

    <div class="image-row big-row">
    <p><img src="media/bruhmoment (sphere, linear).png" /></p>
    <p><img src="media/nearest.png" /></p>
    </div>

    <figure>
    <p> left = spherical interpolation, right = nearest neighbor interpolation </p>
    </figure>
    
    <h2> Part 3: The Morph Sequence </h2>

    <p> I use the functions from part 2 but adjust the t value (crossblur factor) to make a morph sequence.  </p>

     <div class="image-row big-row">
    <p><img src="media/maya_to_wony_gif.gif" /></p>
    </div>

    <h2> Part 4: The Average Face </h2>

    <p> <b> Note:</b> For part 4 and 5, I noticed there were sometimes some black dots in the images. These were coming from the polygon perimeter function, and when removing them the dots went away as well. Therefore, I reran some of the code chunks and replaced my original photos with dots with the non-dot version for photos where the black dots were very bothersome. </p>

    <p> For this part, I use the Danes dataset to get photos of Danish women and average them together to create the portrait of an average Danish person. To get the average person, I morphed each image onto the average points (mean of the correspondences). To warp an individual face onto the average face, I use the morph function and set warp to 1 and dissolve to 0. </p>

    <p> Note: I accidentally defined my own correspondences instead of using the ones in the asf files. Since I only defined 25 (while I think the asf files had way more than 25), my version of the average face doesn't look as good as a version using the points from the asf files. </p>

    <div class="image-row big-row">
    <p><img src="media/average_face.png" /></p>
    </div>
    <figure>
    <p> The Average Danish Woman (at least according to my 25 points) </p>
    </figure>

    <div class="image-row big-row">
    <p><img src="media/w3.bmp" /></p>
    <p><img src="media/w3_average_new.png" /></p>
    </div>

    <figure>
    <p> left = a Danish woman, right = morphed to the average Danish face </p>
    </figure>

    <div class="image-row big-row">
    <p><img src="media/w6.bmp" /></p>
    <p><img src="media/w6_average_new.png" /></p>
    </div>

    <figure>
    <p> left = another Danish woman, right = morphed to the average Danish face </p>
    </figure>

    <div class="image-row big-row">
    <p><img src="media/maya_dane_dim.png" /></p>
    <p><img src="media/average_maya.png" /></p>
    <p><img src="media/maya_average.png" /></p>   
    </div>

    <figure>
    <p> My face morphed onto the average Danish and vice versa.  </p>
    </figure>

    <h2> Part 5: Caricatures: Extrapolating from the Mean </h2>

    <p> To make a caricature, I extrapolate my points from the mean. I multiply the subtracted points by an alpha factor. Alpha > 1 represents how much of a caricature I want to have. I tried multiple alpha values: </p>
    
    <div class="image-row big-row">
    <p><img src="media/caricature_1.png" /></p>
    <p><img src="media/caricature_2.png" /></p>
    </div>

    <h2> Part 6: Bells and Whistles </h2>

    <p> I am a half white American. What would I look like if I was a fully white American? </p>
    <div class="image-row mid-row">
    <p><img src="media/maya_dim_of_white_woman.png" /></p>
    <p><img src="media/white_woman.jpg" /></p>
    </div>

    <figure>
    <p> Above is a portrait of the average white woman that I found on the internet. </p>
    </figure>

    <div class="image-row big-row">
    <p><img src="media/warppoint5.png" /></p>
    <p><img src="media/dissolvepoint5.png" /></p> 
    <p><img src="media/equal.png" /></p>
    </div>

    <figure>
    <p> To warp just the shape, I increase just the warp factor. To warp the colors, I increase just the dissolve factor. To get the true morph, I set both factors to the same value. Left to right: 0.5 warp, 0.5 dissolve, 0.5 both</p>
    </figure>
    
    
    
    <h2> Conclusion </h2>
    <p> In this project I played around with faces. One key takeaway is that face morphing doesn't use some fancy technology like neural networks or ML algorithms -- in fact, it is just linear algebra. I also learned that in order for face morphing to work well, I need two images that are aligned or else it doesn't work that well. </p>

    
    
</body>
</html>
